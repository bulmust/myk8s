#! Loki Configuration
loki:
  config: |
    auth_enabled: true

    querier:
      multi_tenant_queries_enabled: true

    server:
      {{- toYaml .Values.loki.server | nindent 6 }}

    common:
      compactor_address: http://{{ include "loki.compactorFullname" . }}:3100

    distributor:
      ring:
        kvstore:
          store: memberlist

    memberlist:
      join_members:
        - {{ include "loki.fullname" . }}-memberlist

    ingester_client:
      grpc_client_config:
        grpc_compression: gzip

    ingester:
      lifecycler:
        ring:
          kvstore:
            store: memberlist
          replication_factor: 1
      chunk_idle_period: 30m
      chunk_block_size: 262144
      chunk_encoding: snappy
      chunk_retain_period: 1m
      max_transfer_retries: 0
      wal:
        dir: /var/loki/wal

    limits_config:
      enforce_metric_name: false
      reject_old_samples: true
      reject_old_samples_max_age: 168h
      max_cache_freshness_per_query: 10m
      split_queries_by_interval: 15m

    {{- if .Values.loki.schemaConfig}}
    schema_config:
    {{- toYaml .Values.loki.schemaConfig | nindent 2}}
    {{- end}}
    {{- if .Values.loki.storageConfig}}
    storage_config:
    {{- if .Values.indexGateway.enabled}}
    {{- $indexGatewayClient := dict "server_address" (printf "dns:///%s:9095" (include "loki.indexGatewayFullname" .)) }}
    {{- $_ := set .Values.loki.storageConfig.boltdb_shipper "index_gateway_client" $indexGatewayClient }}
    {{- end}}
    {{- toYaml .Values.loki.storageConfig | nindent 2}}
    {{- if .Values.memcachedIndexQueries.enabled }}
      index_queries_cache_config:
        memcached_client:
          addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedIndexQueriesFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
          consistent_hash: true
    {{- end}}
    {{- end}}

    runtime_config:
      file: /var/{{ include "loki.name" . }}-runtime/runtime.yaml

    chunk_store_config:
      max_look_back_period: 0s
      {{- if .Values.memcachedChunks.enabled }}
      chunk_cache_config:
        embedded_cache:
          enabled: false
        memcached_client:
          consistent_hash: true
          addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedChunksFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
      {{- end }}
      {{- if .Values.memcachedIndexWrites.enabled }}
      write_dedupe_cache_config:
        memcached_client:
          consistent_hash: true
          addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedIndexWritesFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
      {{- end }}

    table_manager:
      retention_deletes_enabled: false
      retention_period: 0s

    query_range:
      align_queries_with_step: true
      max_retries: 5
      cache_results: true
      results_cache:
        cache:
          {{- if .Values.memcachedFrontend.enabled }}
          memcached_client:
            addresses: dnssrv+_memcached-client._tcp.{{ include "loki.memcachedFrontendFullname" . }}.{{ .Release.Namespace }}.svc.{{ .Values.global.clusterDomain }}
            consistent_hash: true
          {{- else }}
          embedded_cache:
            enabled: true
            ttl: 24h
          {{- end }}

    frontend_worker:
      {{- if .Values.queryScheduler.enabled }}
      scheduler_address: {{ include "loki.querySchedulerFullname" . }}:9095
      {{- else }}
      frontend_address: {{ include "loki.queryFrontendFullname" . }}-headless:9095
      {{- end }}

    frontend:
      log_queries_longer_than: 5s
      compress_responses: true
      {{- if .Values.queryScheduler.enabled }}
      scheduler_address: {{ include "loki.querySchedulerFullname" . }}:9095
      {{- end }}
      tail_proxy_url: http://{{ include "loki.querierFullname" . }}:3100

    compactor:
      working_directory: /var/loki/compactor
      shared_store: filesystem

    ruler:
      storage:
        type: local
        local:
          directory: /etc/loki/rules
      ring:
        kvstore:
          store: memberlist
      rule_path: /tmp/loki/scratch
      alertmanager_url: https://alertmanager.xx
      external_url: https://alertmanager.xx
  structuredConfig:
    analytics:
      reporting_enabled: false
    compactor:
      compaction_interval: 30m
      retention_delete_delay: 2h
      retention_delete_worker_count: 150
      retention_enabled: true
      shared_store: s3
    limits_config:
      retention_period: 5d
    # https://grafana.com/docs/loki/latest/operations/storage/schema/
    schema_config:
      configs:
        #! TSDB schema
        - from: "2024-06-01"
          store: tsdb
          index:
            period: 24h
            prefix: loki_index_
          object_store: s3
          schema: v13
        #! boltdb-shipper schema
        # - from: "2024-04-01"
        #   index:
        #     period: 24h
        #     prefix: loki_index_
        #   object_store: s3
        #   schema: v13
        #   store: boltdb-shipper
    storageConfig:
      tsdb_shipper:
        active_index_directory: /data/tsdb-index
        cache_location: /data/tsdb-cache
      aws:
        s3forcepathstyle: true
        bucketnames: loki-boltdb-shipper
        endpoint: minio:9000
        access_key_id: bulmust
        secret_access_key: bulmustbulmust
        insecure: true
      # boltdb_shipper:
      #   shared_store: s3
      filesystem: null
    
    querier:
      max_concurrent: 10

#! Ingester Pod
ingester:
  extraArgs:
    - -config.expand-env=true
  replicas: 1
  # If you want to 3 replicas, you have to define max unavailable as 1
  # replicas: 3
  # maxUnavailable: 1
  # If you DONT want to spread the replicas across the nodes, you should define the affinity as below
  # affinity: []
  
  persistence:
    enabled: true
    size: 3Gi

#! Distributor Pod
distributor:
  extraArgs:
    - -config.expand-env=true

#! Querier Pod
querier:
  extraArgs:
    - -config.expand-env=true
  replicas: 1
  # If you want to 3 replicas, you have to define max unavailable as 1
  # replicas: 3
  # maxUnavailable: 1
  # If you DONT want to spread the replicas across the nodes, you should define the affinity as below
  # affinity: []

#! Query Frontend Pod
queryFrontend:
  extraArgs:
    - -config.expand-env=true
  replicas: 1
  # If you want to 3 replicas, you have to define max unavailable as 1
  # replicas: 3
  # maxUnavailable: 1
  # If you DONT want to spread the replicas across the nodes, you should define the affinity as below
  # affinity: []

#! Table Manager Pod
tableManager:
  enabled: false

#! Ingress
ingress:
  enabled: false

#! Gateway Pod
gateway:
  enabled: true
  ingress:
    enabled: true
    ingressClassName: nginx
    annotations:
      cert-manager.io/cluster-issuer: local-ca-cert-issuer
      nginx.org/proxy-buffer-size: 8k
      nginx.org/proxy-send-timeout: "600s"
      nginx.org/proxy-read-timeout: "600s"
      nginx.org/proxy-connect-timeout: "600s"
      nginx.org/client-header-timeout: "600s"
      nginx.org/client-body-timeout: "600s"
      nginx.org/proxy-request-buffering: "off"
    hosts:
      - host: loki.localhost
        paths:
          - path: /
            pathType: Prefix
    tls:
      - secretName: loki-tls
        hosts:
          - loki.localhost
  nginxConfig:
    serverSnippet: client_max_body_size 200M;
    httpSnippet: client_max_body_size 200M;

#! Compactor Pod
compactor:
  enabled: true
  # extraVolumes:
  #   - name: data
  #     emptyDir: {}
  # extraVolumeMounts:
  #   - name: data
  #     mountPath: /var/loki
  extraArgs:
    - -config.expand-env=true
  persistence:
    enabled: true
    size: 2Gi
